{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThePain99/AcademicPrediction/blob/master/AcademicPredictionAlgorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z_FNvm_mfi3I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tkinter import filedialog, Tk\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import webbrowser\n",
        "from openpyxl.worksheet.dimensions import DimensionHolder, ColumnDimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seleccionar_archivo_excel():\n",
        "    \"\"\"Permite al usuario seleccionar un archivo Excel y devuelve la ruta del archivo.\"\"\"\n",
        "    root = Tk()\n",
        "    root.withdraw()\n",
        "    ruta_archivo = filedialog.askopenfilename(title=\"Seleccione un archivo Excel\", filetypes=[(\"Archivos Excel\", \"*.xls;*.xlsx\")])\n",
        "    return ruta_archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ajustar_valores(valor):\n",
        "    \"\"\"Convierte el valor a float y lo ajusta en el rango [0, 20]. Si no es convertible, devuelve 0.\"\"\"\n",
        "    try:\n",
        "        valor = float(valor)\n",
        "        return max(0, min(20, valor))\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def procesar_hoja(df, nombre_hoja):\n",
        "    \"\"\"Procesa la hoja del Excel ajustando los valores de las notas.\"\"\"\n",
        "    if df.empty:\n",
        "        return f\"Error: La hoja '{nombre_hoja}' está completamente vacía.\"\n",
        "\n",
        "    df.iloc[:, 1:] = df.iloc[:, 1:].applymap(ajustar_valores)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def guardar_en_excel(df_predicciones):\n",
        "    \"\"\"Guarda el DataFrame de predicciones en un archivo Excel y lo abre automáticamente.\"\"\"\n",
        "    root = Tk()\n",
        "    root.withdraw()\n",
        "    file_path = filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Archivos Excel\", \"*.xlsx\")])\n",
        "    \n",
        "    if not file_path:\n",
        "        return\n",
        "\n",
        "    with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
        "        df_predicciones.to_excel(writer, sheet_name=\"ACADEMAI\", index=False)\n",
        "        \n",
        "        # Ajustar automáticamente el tamaño de las columnas\n",
        "        for column in writer.sheets[\"ACADEMAI\"].columns:\n",
        "            max_length = 0\n",
        "            column = [cell for cell in column]\n",
        "            for cell in column:\n",
        "                try:\n",
        "                    if len(str(cell.value)) > max_length:\n",
        "                        max_length = len(cell.value)\n",
        "                except:\n",
        "                    pass\n",
        "            adjusted_width = (max_length + 2)\n",
        "            writer.sheets[\"ACADEMAI\"].column_dimensions[column[0].column_letter].width = adjusted_width\n",
        "\n",
        "    webbrowser.open(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando hoja: Grado x\n",
            "Procesando hoja: Grado xx\n",
            "Entrenando modelo para: Curso A\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 366.8086 - mae: 19.1522 - val_loss: 9.2682 - val_mae: 3.0444\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 371.0298 - mae: 19.2621 - val_loss: 6.4828 - val_mae: 2.5461\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 260.3250 - mae: 16.1346 - val_loss: 4.2076 - val_mae: 2.0512\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 143.6064 - mae: 11.9836 - val_loss: 2.6233 - val_mae: 1.6197\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 211.9053 - mae: 14.5570 - val_loss: 1.5292 - val_mae: 1.2366\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 246.4725 - mae: 15.6994 - val_loss: 0.7005 - val_mae: 0.8370\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 168.8370 - mae: 12.9937 - val_loss: 0.1442 - val_mae: 0.3798\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 183.7226 - mae: 13.5544 - val_loss: 0.0072 - val_mae: 0.0846\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 221.2889 - mae: 14.8758 - val_loss: 0.3106 - val_mae: 0.5573\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 341.7208 - mae: 18.4857 - val_loss: 1.0473 - val_mae: 1.0234\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 66.7248 - mae: 8.1685 - val_loss: 2.2561 - val_mae: 1.5020\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 93.5663 - mae: 9.6730 - val_loss: 3.8978 - val_mae: 1.9743\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 21.2261 - mae: 4.6072 - val_loss: 5.8617 - val_mae: 2.4211\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.5559 - mae: 1.2474 - val_loss: 8.1030 - val_mae: 2.8466\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 79.4959 - mae: 8.9160 - val_loss: 10.4858 - val_mae: 3.2382\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0158 - mae: 0.1259 - val_loss: 12.7681 - val_mae: 3.5732\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.0394 - mae: 1.7434 - val_loss: 15.1329 - val_mae: 3.8901\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 20.9674 - mae: 4.5790 - val_loss: 17.6721 - val_mae: 4.2038\n",
            "Error al leer el archivo: Failed to convert a NumPy array to a Tensor (Unsupported object type float).\n"
          ]
        }
      ],
      "source": [
        "# Selecciona el archivo Excel con las notas\n",
        "nombre_archivo = seleccionar_archivo_excel()\n",
        "if nombre_archivo:\n",
        "    _, extension = os.path.splitext(nombre_archivo)\n",
        "    if extension not in ['.xls', '.xlsx']:\n",
        "        print(\"Error: El archivo no es de tipo Excel.\")\n",
        "    else:\n",
        "        try:\n",
        "            # Leer todas las hojas del archivo Excel\n",
        "            hojas = pd.read_excel(nombre_archivo, sheet_name=None, engine='openpyxl')\n",
        "            dfs = []\n",
        "\n",
        "            # Procesar cada hoja ajustando los valores\n",
        "            for nombre_hoja, df in hojas.items():\n",
        "                print(f\"Procesando hoja: {nombre_hoja}\")\n",
        "                df = procesar_hoja(df, nombre_hoja)\n",
        "                dfs.append(df)\n",
        "\n",
        "            # Crear un DataFrame para las predicciones con la columna 'Alumno'\n",
        "            df_predicciones = dfs[-1][['Alumno']].copy()\n",
        "\n",
        "            # Entrenar el modelo y predecir para cada curso\n",
        "            for curso in dfs[0].columns[1:]:\n",
        "                print(f\"Entrenando modelo para: {curso}\")\n",
        "\n",
        "                X = []\n",
        "                y = []\n",
        "\n",
        "                # Recopilar datos de entrenamiento: Características y objetivos\n",
        "                for idx, df in enumerate(dfs[:-1]):\n",
        "                    features = df.drop(columns=[\"Alumno\"]).values.tolist()\n",
        "                    targets = dfs[idx+1][curso].values\n",
        "                    X.extend(features)\n",
        "                    y.extend(targets)\n",
        "\n",
        "                X = np.array(X)\n",
        "                y = np.array(y)\n",
        "                \n",
        "                # Dividir datos en entrenamiento y prueba\n",
        "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "                \n",
        "                # Configuración de la red neuronal profunda\n",
        "                model = keras.Sequential([\n",
        "                    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "                    keras.layers.Dropout(0.3),\n",
        "                    keras.layers.Dense(64, activation='relu'),\n",
        "                    keras.layers.Dropout(0.2),\n",
        "                    keras.layers.Dense(32, activation='relu'),\n",
        "                    keras.layers.Dense(1)\n",
        "                ])\n",
        "                \n",
        "                model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "                \n",
        "                # Aplicar detención temprana para evitar el sobreajuste\n",
        "                early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "                \n",
        "                model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "                \n",
        "                # Predecir para el último grado ingresado\n",
        "                predicciones = model.predict(dfs[-1].drop(columns=[\"Alumno\"]).values)\n",
        "                predicciones = np.clip(predicciones, 0, 20)  # Asegurar valores en el rango [0,20]\n",
        "                predicciones = predicciones.round(2)  # Asegurarse de que esté redondeado a 2 decimales\n",
        "                df_predicciones[curso + ' Predicted'] = predicciones\n",
        "\n",
        "            # Guardar predicciones en un nuevo archivo Excel\n",
        "            guardar_en_excel(df_predicciones)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error al leer el archivo: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNDLCr3/1CBysL3Yt3uyUZY",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (vanilla)",
      "language": "python",
      "name": "vanilla"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
