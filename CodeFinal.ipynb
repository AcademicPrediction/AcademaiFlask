{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Procesando hoja: Grado x\n",
            "Procesando hoja: Grado xx\n",
            "Entrenando modelo para: Curso A\n",
            "Creando un nuevo modelo...\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 143.2603 - mae: 11.9691 - val_loss: 1.2046 - val_mae: 1.0975\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 157.2960 - mae: 12.5418 - val_loss: 2.5363 - val_mae: 1.5926\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 205.1282 - mae: 14.3223 - val_loss: 4.7818 - val_mae: 2.1867\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 183.4641 - mae: 13.5449 - val_loss: 7.6657 - val_mae: 2.7687\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 139.0237 - mae: 11.7908 - val_loss: 11.3427 - val_mae: 3.3679\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 81.9720 - mae: 9.0538 - val_loss: 15.5132 - val_mae: 3.9387\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 82.5704 - mae: 9.0868 - val_loss: 20.5249 - val_mae: 4.5304\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 139.2478 - mae: 11.8003 - val_loss: 26.1609 - val_mae: 5.1148\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 38.0170 - mae: 6.1658 - val_loss: 32.7377 - val_mae: 5.7217\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 42.9205 - mae: 6.5514 - val_loss: 39.8895 - val_mae: 6.3158\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 110.5777 - mae: 10.5156 - val_loss: 47.7243 - val_mae: 6.9083\n",
            "Error al leer el archivo: Failed to convert a NumPy array to a Tensor (Unsupported object type float).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def ajustar_valores(valor):\n",
        "    try:\n",
        "        valor = float(valor)\n",
        "        return max(0, min(20, valor))\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def procesar_hoja(df, nombre_hoja):\n",
        "    if df.empty:\n",
        "        return f\"Error: La hoja '{nombre_hoja}' está completamente vacía.\"\n",
        "    df.iloc[:, 1:] = df.iloc[:, 1:].applymap(ajustar_valores)\n",
        "    return df\n",
        "\n",
        "def guardar_en_excel(df_predicciones):\n",
        "    file_path = \"resultados_predicciones.xlsx\"\n",
        "    df_predicciones.to_excel(file_path, sheet_name=\"Predicciones\", index=False)\n",
        "\n",
        "modelo_guardado_path = 'my_model.h5'\n",
        "model_existente = os.path.exists(modelo_guardado_path)\n",
        "\n",
        "if model_existente:\n",
        "    print(\"Cargando modelo existente...\")\n",
        "    model = keras.models.load_model(modelo_guardado_path)\n",
        "\n",
        "nombre_archivo = \"Modelo_Excel.xlsx\"\n",
        "\n",
        "try:\n",
        "    hojas = pd.read_excel(nombre_archivo, sheet_name=None, engine='openpyxl')\n",
        "    dfs = []\n",
        "\n",
        "    for nombre_hoja, df in hojas.items():\n",
        "        print(f\"Procesando hoja: {nombre_hoja}\")\n",
        "        df = procesar_hoja(df, nombre_hoja)\n",
        "        dfs.append(df)\n",
        "\n",
        "    df_predicciones = dfs[-1][['Alumno']].copy()\n",
        "\n",
        "    for curso in dfs[0].columns[1:]:\n",
        "        print(f\"Entrenando modelo para: {curso}\")\n",
        "\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        for idx, df in enumerate(dfs[:-1]):\n",
        "            features = df.drop(columns=[\"Alumno\"]).values.tolist()\n",
        "            targets = dfs[idx+1][curso].values\n",
        "            X.extend(features)\n",
        "            y.extend(targets)\n",
        "\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "\n",
        "        if model_existente and model.input_shape[1] == X.shape[1]:\n",
        "            pass  # El modelo existente es compatible con los nuevos datos, no es necesario reconfigurarlo\n",
        "        else:\n",
        "            print(\"Creando un nuevo modelo...\")\n",
        "            model = keras.Sequential([\n",
        "                keras.layers.Dense(128, activation='relu', input_shape=(X.shape[1],)),\n",
        "                keras.layers.Dropout(0.3),\n",
        "                keras.layers.Dense(64, activation='relu'),\n",
        "                keras.layers.Dropout(0.2),\n",
        "                keras.layers.Dense(32, activation='relu'),\n",
        "                keras.layers.Dense(1)\n",
        "            ])\n",
        "            model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "        \n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "        predicciones = model.predict(dfs[-1].drop(columns=[\"Alumno\"]).values)\n",
        "        predicciones = np.clip(predicciones, 0, 20)\n",
        "        df_predicciones[curso + ' Predicted'] = predicciones\n",
        "\n",
        "    for curso in df_predicciones.columns[1:]:\n",
        "        df_predicciones[curso] = df_predicciones[curso].apply(lambda x: round(x, 2))\n",
        "\n",
        "    model.save(modelo_guardado_path)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error al leer el archivo: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (vanilla)",
      "language": "python",
      "name": "vanilla"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
